Calibration, Simulation and Estimation
=========================================

We refer to :boldblue:`calibration` as selection of parameter
values to reconcile model outputs with observed data. Since one of our
modeling goals is to quantitatively evaluate policies we will view calibration
as :boldblue:`estimation`.

The Keane and Wolpin (1997, :cite:`Keane.1997`) model is calibrated to
data on observed individual decisions and experiences.
A :boldblue:`full parametrization` :math:`\theta \in \Theta`
of the model allows to back out information on reward functions and
transition probabilities. We denote :math:`\theta` the vector of
structural parameters out of an admissible parameter space :math:`\Theta`.

The main underlying hypothesis includes that the behavior of the
individual decision-maker is generated by the solution of the model
(see Section :ref:`solution_model`). :boldblue:`The behavioral model`
is governed by the parameters :math:`\theta \in \Theta` which describe
the agent's preferences and beliefs. Embedded in the theoretical model
described in Section :ref:`economic_model` each of them has a specific
economic interpretation. For example, the discounting parameter
:math:`\delta` (as in Equation :eq:`AlternativeSpecificValueFunctions`)
describes the importance of future payoffs relative to today's.

.. rst-class:: centerblue

   The discount factor is pre-defined in ``respy`` and unmutable.
   It is located in params under the key ``delta``.

Under the paradigm of revealed preferences (Samuelson, 1938,
:cite:`Samuelson.1938`) structural preference parameters are estimable
with microdata on individual decisions. Let us assume that we a particular
data set :math:`\mathcal{D}` that includes information for the
:math:`i= 1, \dots, N` individuals in each time period :math:`t=16, \dots, T`.
As outlined in Section :ref:`State Space` the state space consists of both
observables and unobservables. More specifically :math:`\epsilon_{it}` is
only observed by the individual decision-maker. Researcher can observe
the human capital :math:`s_{it}` [#]_ and rewards in each period.
The data :math:`\mathcal{D}` can be represented as

.. math::

   \mathcal{D}  & = \{s_{it}, R_a(s_{it}): i= 1,
   \dots, N; t = 1, \dots, T_i \} \\
   & = \{h_{it}, k_{it}, a_{it}, R_a(s_{it}):i= 1,
   \dots, N; t = 1, \dots, T_i \},

where :math:`T_i` denotes the last period of available observations for
individual :math:`i`. If :math:`\mathcal{D}` is available numerous estimation
procedures exist (Davidson, 2003, :cite:`Davidson.2003`).
Independent of the estimation criterion, for any parametrization
it is necessary to solve for the optimal policy as outlined in Section
:ref:`dynamic_programming_problem`.

.. rst-class::centerblue

   Two estimation criteria are available through ``respy``:

   - Likelihood estimation via ``get_crit_func``
   - Method of simulated moments via ``get_msm_func``

In the following we will outline likelihood based and simulation based
estimation.

Likelihood-based Estimation
---------------------------

Likelihood-based estimation aims to find the parametrization
:math:`\hat{\theta}` that maximizes the probability of observing the given
data :math:`\mathcal{D}` as function of the parametrization
:math:`\theta \in \Theta`. The object of interest is the
:boldblue:`choice probability`

.. math::
   :label: ChoiceProbability

   p_{it}(a_{it}, R_{it}(S_{it})|s_{it}, \theta),

which is defined as the probability of individual :math:`i` to choose
:math:`a_{it}` under the prospect of receiving reward :math:`R_a(S_{it})`
conditional on the observable state space :math:`s_{it}`.

In order to determine :math:`p_{it}(a_{it}, R_{it}(S_{it})|s_{it}, \theta)`
we need to impose parametric assumptions on the distribution of
:math:`\epsilon_{it}`. The assumption of independence across time and
individuals (conditional on :math:`s_{it})` will be maintained.
Notably, each different parametrization induces also a different
probability distribution over the sequence of observed agent choices
and so their state experience.  Maintaining the assumptions on the
stochastic error terms [#]_ the :boldblue:`Likelihood function`
can be expressed as:

.. math::
   :label: LikelihoodFunction

   L(\theta|\mathcal{D}) \equiv \prod_{i=1}^N
   \prod_{t=1}^T p_{it}(a_{it}, R_{it}(S_{it})|s_{it}, \theta).

To find the parameter :math:`\hat{\theta}` that maximizes the Likelihood
function each potential parametrization :math:`\theta \in \Theta` is
evaluated on the observed sample :math:`\mathcal{D}`.

Given the assumption on the stochastic terms imposed by Keane and
Wolpin (1997, :cite:`Keane.1997`) the necessary density to calculate
the choice probabilities includes an integral without a closed-form solution.
It is necessary to rely on numerical integration.
The choice probabilities of the individual decision-makers are simulated.
Replacing the choice probabilities in Equation :eq:`LikelihoodFunction`
with their simulated counterparts leads to the
:boldblue:`Simulated Maximum Likelihood Estimator`
(Manski, 1977, :cite:`Manski.1977`).

.. rst-class:: centerblue

   The implementation in ``respy`` minimizes the simulated
   negative log-likelihood of the observed sample.

After solving the DP problem million-wise we will eventually end up with the
maximum simulated likelihood estimator

.. math::
   :label: MLParameter

   \hat{\theta} \equiv \arg \max_{\theta \in \Theta}
   \prod_{i=1}^N \prod_{t=1}^T p_{it}(a_{it}, R_{it}(S_{it})|s_{it}, \theta).


Simulation based Estimation
---------------------------

Simulation-based estimation aims to find the parametrization
:math:`\hat{\theta}` that minimizes a pre-defined distance criterion between
a simulated data set under :math:`\theta` and the observed data
:math:`\mathcal{D}`.

A first step would be to employ a :boldblue:`Generalized Method of Moments`
(GMM) estimator (Gallant and Tauchen, 1996, :cite:`Gallant.1996`)
that minimizes the distance between moments calculated on the observed data
:math:`M_{\mathcal{D}}` and the analogous model moments :math:`M_S(\theta)`
calculated on the simulated data under :math:`\theta \in \Theta`.
The objective function is given by

.. math::
   :label: GMMFunction

   G(\theta|\mathcal{D}) \equiv (M_{\mathcal{D}} - M_S(\theta))^T ~
   W ~  (M_{\mathcal{D}} - M_S(\theta))^T,

where :math:`W` denotes an appropriate (positive-definite) weighting matrix.

.. rst-class:: centerblue

   The weighting matrix in ``respy`` consists of
   the inverse bootstrap variances of the observed sample moments.

However, similar to the treatment in McFadden (1989, :cite:`McFadden.1989`)
some model moments are difficult (not possible) to derive analytically in the
setting of Keane and Wolpin (1997, :cite:`Keane.1997`).
The :boldblue:`Method of Simulated Moments` (MSM) circumvents this issue.
The model data under :math:`\theta` is simulated :math:`S` times and the
model moments are calculated by averaging over the moments from the simulated
data. For example, the choice probabilities could be obtained as

.. math::
   :label: ModelMoments

   \hat{p}_{it}(\tilde{\mathcal{D}} | \theta) = \dfrac{1}{S}
   \sum_{s=1}^S p_{it}(\mathcal{\tilde{D}}_s|Â \theta),

where :math:`\tilde{\mathcal{D}} = \{ \tilde{\mathcal{D}}_1, \dots,
\tilde{\mathcal{D}}_S\}` denotes the :math:`S` simulations of the model data.

Once the model moments are estimated the MSM estimation is similar to
the GMM estimation. The parameter vector :math:`\hat{\theta}` is estimated
by choosing :math:`\theta` such that the pre-defined distance measure between
data moments and simulated model moments :math:`\hat{M}_{\tilde{S}}(\theta)`
is minimized. The :boldblue:`MSM estimator` is given by

.. math:: 
   :label: SMMEstimator

   \hat{\theta} \equiv \arg \min_{\theta \in \Theta} (M_{\mathcal{D}} -
   \hat{M}_{\tilde{S}}(\theta)(\theta))^T ~ W ~  (M_{\mathcal{D}} -
   \hat{M}_{\tilde{S}}(\theta))^T,

where :math:`\hat{M}_{\tilde{S}}(\theta)` denotes the estimated moments from
the the simulated data :math:`\tilde{\mathcal{D}}`.

.. rst-class:: centerblue

   The implementation of MSM estimation in ``respy`` is extensively
   described in

   - The tutorial on `Methods of Simulated Moments (MSM)
     <https://respy.readthedocs.io/en/latest/how_to_guides/msm.html>`_
   - The tutorial on `How to Estimate Model Parameters with MSM
     <https://respy.readthedocs.io/en/latest/how_to_
     guides/msm_estimation_exercise.html>`_

The work by Eisenhauer, Heckman, and Mosso (2015, :cite:`Eisenhauer.2015`)
compares the performance of the MSM estimator against a standard maximum
likelihood estimator in a simplified dynamic discrete choice model of
schooling. Different to Keane and Wolpin (1994, :cite:`Keane.1994`; 1997,
:cite:`Keane.1997`) their restriction to binary choices of agents allows to
solve for the likelihood analytically and so dispenses the need for
simulation or interpolation. Their ML estimates are close to the ''true''
structural objects of interest while MSM fails to recover some of them.
At p.351 the authors provide a comparison of alternative weighting matrices.

.. rubric:: Footnotes

.. [#] The observable state space :math:`s_{it}` summarizes years of
       completed schooling, work experience, and choices

.. [#] Serial independence, independently distributed across agents
       conditional on :math:`s_{it}`
